export default function Essay() {
    return (
        <div className="essay">
            <h3 className="essay-heading">A Different Perspective (Around 500 words Essay)</h3>
            <p className="essay-text">Project 2 is meant to be run on a Virtual Reality Headset like Oculus Quest. The whole idea of the project is to create an experience that can help a user to overcome the phobia of working in an office environment. However, it was possible to always test the application on a VR headset due to the headset’s limited availability. So, many times, the application was tested on Spatial Simulator Camera which is like a PC game camera where the user can navigate the virtual space using keyboard (WASD keys) and mouse input. In this essay, we will discuss how experiencing this application on a VR Headset differed from experiencing it in a spatial simulator. <br/><br/>Due to the limited availability of VR headsets, testing the application on Spatial Simulator has been a great help. It is very easy to switch between different cameras. One of the great advantages of the spatial simulator is that it is very easy to launch. The user just needs to click the play button in Unity (while having the simulator active) and within few seconds it appears in the game section. Also, small interactions with the help of “onTriggerEnter” and “onCollisionEnter” callbacks can be achieved and tested without the need for a headset. Users can also, test lights, audios, and animation while navigating with the help of the simulator. If the user moves in a different direction, the audio intensity and its directions also seem to change. However, the simulator is like a normal game where the interaction is very limited. It is not possible to grab an interactable item with it. There were a lot of challenges while creating an interactable door to exit from the office and it was one of the major tasks but the spatial simulator was of no use to test this kind of behavior. <br/><br/>On the other hand, experiencing the application on a VR Headset is far superior and immersive as compared to spatial simulators. As soon as you wear the headset, it feels like your application has come to life. Everything looked bigger and clearer. The audio sound was far more spatial (both in terms of space and changing with head movement as well). Navigating with the help of locomotion was so much easier than WASD movements. But the best part was interacting with the environment, you can grab things, throw them anywhere, walk in the virtual space, lie down, look behind the objects. All these features are unable to be tested on a spatial simulator. Experience your work in VR headsets would make you feel even more proud and it also gives a sense of accomplishment and wonder. <br/><br/>Although, VR experience is breathtaking, there are some downsides to it as well. People can experience dizziness while interacting with a VR environment. Image falling, from a building or sliding down a steep slant. It can even get scarier if horror elements are utilized. Another disadvantage of the XR Unity camera to Spatial Simulator is that it takes a lot of time to build your application to the VR headset. I have wasted a lot of time, building the application to VR Headset while Spatial Simulator was left active with a mistake. Then I would have to build again which takes around 2-5 minutes. So, testing every segment of the project in the headset was quite challenging. <br/><br/>Finally, the spatial simulator has a lot of limitations, but beginner-level interactions can be tested on it. It does make the life of a developer pretty easy. However, the complete VR experience can only be achieved through a headset. My recommendation is to use Spatial Simulators to create and placing Audio Sources, lights, materials, game objects with appropriate colliders and physics. However, the scale, spatial sound, interactable objects, and the fine-tuning of the project are meant to be tested with a VR headset.</p>
        </div>
    );
}